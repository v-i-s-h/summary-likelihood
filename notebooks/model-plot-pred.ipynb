{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze models predictions\n",
    "\n",
    "Analysze the models predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import methods\n",
    "import models\n",
    "import datasets\n",
    "import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataset, N=10):\n",
    "    dataloader = DataLoader(dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "    # Get predictions from model\n",
    "    ypreds = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            _ypreds, _ = model.sample_predictions(x, n=N)\n",
    "            if ypreds:\n",
    "                for i in range(N):\n",
    "                    ypreds[i] = torch.cat((ypreds[i], _ypreds[i]), dim=0)\n",
    "            else:\n",
    "                for y2 in _ypreds:\n",
    "                    # y2 is a tensor of shape (B, K)\n",
    "                    ypreds.append(y2)\n",
    "\n",
    "    # Convert to softmax score from log_softmax\n",
    "    yprobs = [torch.exp(_ypreds) for _ypreds in ypreds]\n",
    "    \n",
    "    return yprobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit `model_dir` variable to point to the model you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./../zoo/experiments-termwise-ablation/BinaryMNISTC-53-identity/LeNet/term-all-beta1010-20220402213949/\"\n",
    "\n",
    "# Default paths\n",
    "config_json = os.path.join(model_dir, \"config.json\")\n",
    "ckpt_file = glob.glob(model_dir + '/step=*.ckpt')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open(config_json, 'r'))\n",
    "\n",
    "MethodClass = getattr(methods, config['method'])\n",
    "DatasetClass = getattr(datasets, config['dataset']) # Will automatically detect the dataset for testing\n",
    "ModelClass = getattr(models, config['model'])\n",
    "TransformClass = getattr(transforms, config['transform'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = DatasetClass(**config['ds_params'], split='test', transform=TransformClass())\n",
    "K = testset.n_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MethodClass.load_from_checkpoint(ckpt_file, model=ModelClass(K), strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions from model\n",
    "\n",
    "You can sample multiple predictions from the model for each realization of parameters by setting $N$. The returned\n",
    "variable will be a list with $N$ entries, corresponding to each realizations. If you want average over all realization,\n",
    "you can average over the list entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yscores = get_predictions(model, testset, N=8) # Ask for 8 realizations of NN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yscores[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2cc81e65ac001079a8dbd6b9a2e1804ae2bdf52e129f39c92608ef96e247326a"
  },
  "kernelspec": {
   "display_name": "Python (Bayes)",
   "language": "python",
   "name": "bayes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
