{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze histogram of predicted scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append(\"./../\")\n",
    "sys.path.insert(0, \"./../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats as S\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from tbparse import SummaryReader\n",
    "\n",
    "import methods, models, datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_file(model_dir):\n",
    "    tblog_dir = os.path.join(model_dir, \"tblog\")\n",
    "    events_file = glob.glob(tblog_dir + \"/events.out.tfevents*.1\")[0] # *.1 will be from test\n",
    "\n",
    "    return events_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dirs = [\n",
    "    \"./../zoo/additional-models/fig-1/BinaryMNISTC-1000-53-identity/LeNet/mfvi-sz1000-5-20220827070550\",\n",
    "    \"./../zoo/additional-models/fig-1/BinaryMNISTC-1000-53-identity/LeNet/sl-alpha1e+04-beta-1e-01-1e-01-20221012113746/\",\n",
    "    \"./../zoo/additional-models/fig-1/BinaryMNISTC-1000-53-identity/LeNet/sl-alpha1e+04-beta-1e+00-1e+00-20221012113746\",\n",
    "    \"./../zoo/additional-models/fig-1/BinaryMNISTC-1000-53-identity/LeNet/sl-alpha1e+04-beta-5e+00-5e+00-20221012113746\"\n",
    "]\n",
    "\n",
    "n = len(model_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, n, figsize=(6*n, 3))\n",
    "\n",
    "for _ax, model_dir in zip(ax, model_dirs):\n",
    "    config_json = os.path.join(model_dir, \"config.json\")\n",
    "    event_file = get_event_file(model_dir)\n",
    "    config = json.load(open(config_json, 'r'))\n",
    "    params = config['method_params']\n",
    "\n",
    "    ev = SummaryReader(event_file, pivot=True)\n",
    "    df_scalars = ev.scalars\n",
    "    df_hist = ev.histograms\n",
    "\n",
    "    l = df_hist.iloc[-1]\n",
    "    x = l['y_pred_test/limits']\n",
    "    y = l['y_pred_test/counts']\n",
    "    y = y / y.sum()\n",
    "\n",
    "    # base_measure = S.beta(params['a'], params['b'])\n",
    "    # x2 = np.linspace(0.0, 1.0, 25)\n",
    "    # pdf = base_measure.pdf(x2)\n",
    "\n",
    "    _ax.bar(x, y, width=-0.09, align='edge')\n",
    "    # plt.plot(x2, pdf)\n",
    "    _ax.set_xlim(0.0, 1.0)\n",
    "    _ax.set_ylim(0.0, 0.6)\n",
    "    # plt.title(\n",
    "    #     \"Beta({:.2f}, {:.2f})\".format(params['a'], params['b']) +\n",
    "    #     \"    $\\\\alpha$ = {:.0f}\".format(params['alpha']) +\n",
    "    #     \"    $\\\\lambda_{SL}$ = \"+\"{:.2f}\".format(params['lam_sl'])\n",
    "    # )\n",
    "    _ax.set_xlabel(\"$\\\\hat{p}$\")\n",
    "    _ax.set_ylabel(\"$\\hat{s_{\\\\theta}}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot decision regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build TSNE embeddings of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetClass = getattr(datasets, config['dataset']) # Will automatically detect the dataset for testing\n",
    "TransformClass = getattr(transforms, config['transform'])\n",
    "testset = DatasetClass(**config['ds_params'], split='test', transform=TransformClass())\n",
    "K = testset.n_labels\n",
    "\n",
    "batch_size = 1000\n",
    "dataloader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "batch = next(iter(dataloader))\n",
    "sample_images, sample_target = batch\n",
    "X = sample_images.reshape(batch_size,-1).numpy()\n",
    "X_embedded = TSNE(n_components=2, init='random').fit_transform(X)\n",
    "x = X_embedded[:,0]; y = X_embedded[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get predictions from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataset, N=10):\n",
    "    dataloader = DataLoader(dataset, batch_size=1024, shuffle=False)\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # Get predictions from model\n",
    "    ypreds = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            _ypreds, _ = model.sample_predictions(x, n=N)\n",
    "            if ypreds:\n",
    "                for i in range(N):\n",
    "                    ypreds[i] = torch.cat((ypreds[i], _ypreds[i]), dim=0)\n",
    "            else:\n",
    "                for y2 in _ypreds:\n",
    "                    # y2 is a tensor of shape (B, K)\n",
    "                    ypreds.append(y2)\n",
    "\n",
    "    # Convert to softmax score from log_softmax\n",
    "    yprobs = [torch.exp(_ypreds) for _ypreds in ypreds]\n",
    "    \n",
    "    return yprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = []\n",
    "\n",
    "for model_dir  in model_dirs:\n",
    "    config_json = os.path.join(model_dir, \"config.json\")\n",
    "    ckpt_file = glob.glob(model_dir + '/step=*.ckpt')[-1]\n",
    "\n",
    "    config = json.load(open(config_json, 'r'))\n",
    "\n",
    "    MethodClass = getattr(methods, config['method'])\n",
    "    DatasetClass = getattr(datasets, config['dataset']) # Will automatically detect the dataset for testing\n",
    "    ModelClass = getattr(models, config['model'])\n",
    "    TransformClass = getattr(transforms, config['transform'])\n",
    "\n",
    "    testset = DatasetClass(**config['ds_params'], split='test', transform=TransformClass())\n",
    "    K = testset.n_labels\n",
    "\n",
    "    model = MethodClass.load_from_checkpoint(ckpt_file, model=ModelClass(K), strict=False)\n",
    "    torch.manual_seed(24)\n",
    "    _ypreds, _ = model.sample_predictions(sample_images, n=1)\n",
    "    yprobs = torch.exp(_ypreds[0].detach())\n",
    "    _z = yprobs[:,1].numpy()\n",
    "\n",
    "    z.append(_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = n, figsize = (5*n, 3.4))\n",
    "\n",
    "xlim = (-25,25); ylim = (-25,25)\n",
    "levels = 15; ms = 1\n",
    "\n",
    "for _ax, _z in zip(ax, z):\n",
    "    # _ax.tricontour(x, y, _z, levels=levels, linewidths=0.5, colors='k')\n",
    "    cntr = _ax.tricontourf(x, y, _z, levels=levels, cmap=\"RdBu_r\", vmin=0.0, vmax=1.0) \n",
    "    fig.colorbar(cntr, ax=_ax)\n",
    "    _ax.set(xlim=xlim, ylim=ylim)\n",
    "    _ax.plot(x, y, 'ko', ms=ms)\n",
    "    _ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Bayes)",
   "language": "python",
   "name": "bayes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "13ede2aa3846a80420e8be59016e3b86d734ba47be24b4292330ac6ad96136da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
