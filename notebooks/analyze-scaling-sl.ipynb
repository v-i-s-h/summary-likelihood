{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of Summary likelihood term\n",
    "\n",
    "This notebook explores the effect of scaling summary likelihood term. The models are trained\n",
    "with `slurm-scripts/submit_mnistc_scale.sh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchmetrics\n",
    "\n",
    "import methods\n",
    "import models\n",
    "import datasets\n",
    "import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_marginal_predictions(model, dataset, N=10):\n",
    "    dataloader = DataLoader(dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "    # Get predictions from model\n",
    "    ytrue = []\n",
    "    ypreds = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            _ypreds, _ = model.sample_predictions(x, n=N)\n",
    "            if ypreds:\n",
    "                for i in range(N):\n",
    "                    ypreds[i] = torch.cat((ypreds[i], _ypreds[i]), dim=0)\n",
    "            else:\n",
    "                for y2 in _ypreds:\n",
    "                    # y2 is a tensor of shape (B, K)\n",
    "                    ypreds.append(y2)\n",
    "            ytrue.append(y)\n",
    "\n",
    "    # Convert to softmax score from log_softmax\n",
    "    yprobs = [torch.exp(_ypreds) for _ypreds in ypreds]\n",
    "    # Compute mean and std\n",
    "    yprob_marginal = torch.stack([_yprob.sum(dim=0) for _yprob in yprobs])\n",
    "    y_std, y_mean = torch.std_mean(yprob_marginal, dim=0)\n",
    "\n",
    "    # compure accuracy\n",
    "    ytrue = torch.cat(ytrue, dim=0)\n",
    "    acc = []\n",
    "    pred_entropy = []\n",
    "    for _y in yprobs:\n",
    "        _acc = torchmetrics.functional.accuracy(_y, ytrue)\n",
    "        acc.append(_acc.numpy())\n",
    "        \n",
    "        _ent = torch.mean(torch.sum(_y * -torch.log(_y), dim=1))\n",
    "        pred_entropy.append(_ent.numpy())\n",
    "\n",
    "    y_mean = y_mean.numpy()\n",
    "    y_std = y_std.numpy() / np.sqrt(N)\n",
    "\n",
    "    # accuracy\n",
    "    acc_mean = np.mean(acc)\n",
    "    acc_std = np.std(acc) / np.sqrt(N)\n",
    "    \n",
    "    # predictive entropy\n",
    "    ent_mean = np.mean(pred_entropy)\n",
    "    ent_std = np.std(pred_entropy) / np.sqrt(N)\n",
    "\n",
    "    return y_mean, y_std, acc_mean, acc_std, ent_mean, ent_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"./../zoo/sl-scaling/BinaryMNISTC-53-identity/LeNet/\"\n",
    "\n",
    "# model_dirs = [f for f in os.listdir(root_dir) if re.match(r'.+-nw-[1|2]-\\d+', f)]\n",
    "model_dirs = os.listdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result = namedtuple(\"Result\",\n",
    "    \"model_id lam_sl corruption \" \n",
    "    \"y_mean_0 y_mean_1 y_std_0 y_std_1 \" \n",
    "    \"acc_mean acc_std \" \n",
    "    \"ent_mean ent_std\")\n",
    "results = []\n",
    "for _model_dir in model_dirs:\n",
    "    model_dir = os.path.join(root_dir, _model_dir)\n",
    "    # Default paths\n",
    "    config_json = os.path.join(model_dir, \"config.json\")\n",
    "    ckpt_file = os.path.join(model_dir, \"last.ckpt\")\n",
    "\n",
    "    config = json.load(open(config_json, 'r'))\n",
    "\n",
    "    MethodClass = getattr(methods, config['method'])\n",
    "    DatasetClass = getattr(datasets, config['dataset'])\n",
    "    ModelClass = getattr(models, config['model'])\n",
    "    TransformClass = getattr(transforms, config['transform'])\n",
    "\n",
    "    testset = DatasetClass(**config['ds_params'], split='test', transform=TransformClass())\n",
    "    K = testset.n_labels\n",
    "\n",
    "    model = MethodClass.load_from_checkpoint(\n",
    "            os.path.join(model_dir, \"last.ckpt\"),\n",
    "            model=ModelClass(K))\n",
    "    \n",
    "    # Test for different corruptions\n",
    "    for corruption in testset.corruptions:\n",
    "        testset = DatasetClass(\n",
    "                    config['ds_params']['labels'], \n",
    "                    split='test', \n",
    "                    corruption=corruption,\n",
    "                    transform=TransformClass())\n",
    "\n",
    "        y_mean, y_std, acc_mean, acc_std, ent_mean, ent_std = get_marginal_predictions(model, testset, N=50)\n",
    "\n",
    "    \n",
    "        results.append(\n",
    "            Result(\n",
    "                _model_dir, model.lam_sl, corruption,\n",
    "                y_mean[0], y_mean[1], y_std[0], y_std[1],\n",
    "                acc_mean, acc_std,\n",
    "                ent_mean, ent_std\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results).sort_values(by='lam_sl').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predictive marginal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_results[df_results.corruption == 'identity']\n",
    "gdf = df.groupby(by='lam_sl')\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "for k, _df in gdf:\n",
    "    y_mean = _df.y_mean_1\n",
    "    x = [k] * len(y_mean)\n",
    "    plt.scatter(x, y_mean, marker='o', s= 50 + 30 * _df.y_std_1)\n",
    "plt.hlines(testset.n_classes[1], \n",
    "            1e-5, 1e+2,\n",
    "            colors='k', linestyles=':')\n",
    "plt.xscale('log')\n",
    "plt.title(\"Predictive marginal distribution\")\n",
    "plt.xlabel(\"$\\\\lambda_{SL}$\")\n",
    "plt.ylabel(\"Predictive probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predictive accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_results[df_results.corruption == 'identity']\n",
    "gdf = df.groupby(by='lam_sl')\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "for k, _df in gdf:\n",
    "    y_mean = _df.acc_mean\n",
    "    x = [k] * len(y_mean)\n",
    "    plt.scatter(x, y_mean, marker='o', s= 50 + 1e5 * _df.acc_std)\n",
    "plt.xscale('log')\n",
    "plt.title(\"Accuracy of model\")\n",
    "plt.xlabel(\"$\\\\lambda_{SL}$\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predictive entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_results[df_results.corruption == 'identity']\n",
    "gdf = df.groupby(by='lam_sl')\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "for k, _df in gdf:\n",
    "    y_mean = _df.ent_mean\n",
    "    x = [k] * len(y_mean)\n",
    "    plt.scatter(x, y_mean, marker='o', s= 50 + 1e5 * _df.ent_std)\n",
    "plt.xscale('log')\n",
    "plt.title(\"Predictive entropy\")\n",
    "plt.xlabel(\"$\\\\lambda_{SL}$\")\n",
    "plt.ylabel(\"Entropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot average accuracy for each corruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_results.groupby(['lam_sl', 'corruption'])['acc_mean'].mean().reset_index()\n",
    "df = df.pivot(\"corruption\", \"lam_sl\", \"acc_mean\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "sns.heatmap(df, ax=ax)\n",
    "ax.set(xlabel=\"$\\\\lambda_{SL}$\")\n",
    "plt.title(\"Average accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot average predictive entropy for different corruptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_results.groupby(['lam_sl', 'corruption'])['ent_mean'].mean().reset_index()\n",
    "df = df.pivot(\"corruption\", \"lam_sl\", \"ent_mean\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "sns.heatmap(df, ax=ax)\n",
    "ax.set(xlabel=\"$\\\\lambda_{SL}$\")\n",
    "plt.title(\"Predictive entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2cc81e65ac001079a8dbd6b9a2e1804ae2bdf52e129f39c92608ef96e247326a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('bayes')",
   "language": "python",
   "name": "python397jvsc74a57bd013ede2aa3846a80420e8be59016e3b86d734ba47be24b4292330ac6ad96136da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
