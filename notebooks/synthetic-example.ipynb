{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create synthetic data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 10 # number of dimensions of data\n",
    "R = 10 # repeats of same data point\n",
    "\n",
    "X0 = 2*np.eye(D) - 1\n",
    "X = np.repeat(X0, repeats=R, axis=0)\n",
    "y = np.triu(np.ones((D, R))).flatten().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./../') # for bayesian torch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from bayesian_torch.layers import LinearReparameterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = LinearReparameterization(in_features=in_dim,\n",
    "                        out_features=2*in_dim,\n",
    "                        prior_mean=0.0,\n",
    "                        prior_variance=1.0,\n",
    "                        posterior_mu_init=0.0,\n",
    "                        posterior_rho_init=-3.0)\n",
    "        self.fc2 = LinearReparameterization(in_features=2*in_dim,\n",
    "                        out_features=2*in_dim,\n",
    "                        prior_mean=0.0,\n",
    "                        prior_variance=1.0,\n",
    "                        posterior_mu_init=0.0,\n",
    "                        posterior_rho_init=-3.0)\n",
    "        self.fc3 = LinearReparameterization(in_features=2*in_dim,\n",
    "                        out_features=2,\n",
    "                        prior_mean=0.0,\n",
    "                        prior_variance=1.0,\n",
    "                        posterior_mu_init=0.0,\n",
    "                        posterior_rho_init=-3.0)\n",
    "        \n",
    "        self.num_classes = 2\n",
    "        \n",
    "    def forward(self, x):\n",
    "        kl_sum = 0\n",
    "        \n",
    "        x, kl = self.fc1(x)\n",
    "        kl_sum += kl\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x, kl = self.fc2(x)\n",
    "        kl_sum += kl\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x, kl = self.fc3(x)\n",
    "        kl_sum += kl\n",
    "        \n",
    "        out = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return out, kl_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.tensor(x, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y)\n",
    "        self.length = self.x.shape[0]\n",
    "        \n",
    "        self.n_labels = 2\n",
    " \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "trainset = dataset(X,y)\n",
    "\n",
    "#DataLoader\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(trainset, batch_size=10*batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training for MFVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import MFVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "mc_samples = 16\n",
    "\n",
    "model = FCN(D)\n",
    "method_params = MFVI.populate_missing_params({}, trainset)\n",
    "pl_model = MFVI(model, **method_params, mc_samples=mc_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(max_epochs=epochs, enable_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(pl_model, trainloader, trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MFVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1000 # samples for each datapoint\n",
    "\n",
    "results = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for j in range(X0.shape[0]): # Take for each point\n",
    "        x = torch.tensor(X0[j, :].reshape(1, -1), dtype=torch.float32)\n",
    "        \n",
    "        output_ = []\n",
    "        for _m in range(m):\n",
    "            output, _ = model(x)\n",
    "            output_.append(torch.exp(output[:, 1]))\n",
    "        \n",
    "        preds = torch.cat(output_).numpy()\n",
    "        \n",
    "        # Label for this sample\n",
    "        p0 = j / D # probability that label is zero\n",
    "        labels = (np.random.rand(*preds.shape) > p0).astype(int) # This will the label distribution for this sample\n",
    "        \n",
    "        results[j] = (preds, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "from torchmetrics.functional import calibration_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_calibration_curve(results, title):\n",
    "    ypred = np.concatenate([v[0] for k, v in results.items()])\n",
    "    ytrue = np.concatenate([v[1] for k, v in results.items()])\n",
    "    \n",
    "    nbins = 20\n",
    "    prob_true, prob_pred = calibration_curve(ytrue, ypred, n_bins=20)\n",
    "    hist, edges = np.histogram(ypred, bins=np.arange(0.0, 1.01, 1/nbins))\n",
    "#     hist, edges = np.histogram(ypred)\n",
    "    hist = hist / hist.sum()\n",
    "    edges = 0.50 * (edges[:-1] + edges[1:])\n",
    "    \n",
    "    ece = calibration_error(torch.tensor(ypred), torch.tensor(ytrue))\n",
    "    \n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(prob_true, prob_pred)\n",
    "    plt.plot([0, 1], [0, 1], ls=':', c='k', alpha=0.25)\n",
    "    plt.bar(edges, hist, width=1.0/nbins, align='center', color='k', alpha=0.10)\n",
    "    plt.xlim(0.0, 1.0)\n",
    "    plt.ylim(0.0, 1.0)\n",
    "    plt.title('{} (ECE = {:.3f})'.format(title, ece))\n",
    "    \n",
    "    r = {\n",
    "        'prob_true': prob_true,\n",
    "        'prob_pred': prob_pred,\n",
    "        'edges': edges,\n",
    "        'hist': hist,\n",
    "        'ece': ece\n",
    "    }\n",
    "    \n",
    "    return r, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_mfvi, fig = plot_calibration_curve(results, title=\"MFVI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test SL - Sweep $\\lambda_{SL}$ value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import SummaryLikelihood as SL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "mc_samples = 16\n",
    "m = 1000 # samples for each datapoint\n",
    "\n",
    "results_sl = {}\n",
    "def run_experiment(lam_sl):\n",
    "    # Train model\n",
    "    model = FCN(D)\n",
    "    method_params = SL.populate_missing_params({'beta': True, 'a': 1, 'b': 1, 'alpha': 100, 'lam_sl': lam_sl}, trainset)\n",
    "    pl_model = SL(model, **method_params, mc_samples=mc_samples)\n",
    "    trainer = Trainer(max_epochs=epochs, enable_progress_bar=False)    \n",
    "    trainer.fit(pl_model, trainloader, trainloader)\n",
    "    \n",
    "    # Evaluate\n",
    "    results = {}\n",
    "    with torch.no_grad():\n",
    "        for j in range(X0.shape[0]): # Take for each point\n",
    "            x = torch.tensor(X0[j, :].reshape(1, -1), dtype=torch.float32)\n",
    "\n",
    "            output_ = []\n",
    "            for _m in range(m):\n",
    "                output, _ = model(x)\n",
    "                output_.append(torch.exp(output[:, 1]))\n",
    "\n",
    "            preds = torch.cat(output_).numpy()\n",
    "\n",
    "            # Label for this sample\n",
    "            p0 = j / D # probability that label is zero\n",
    "            labels = (np.random.rand(*preds.shape) > p0).astype(int) # This will the label distribution for this sample\n",
    "\n",
    "            results[j] = (preds, labels)\n",
    "            \n",
    "    r, fig = plot_calibration_curve(results, title = \"SL ($\\\\lambda_{} = {:.0e}$)\".format('{SL}', lam_sl))\n",
    "    \n",
    "    return r, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_sl = [0.0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0]\n",
    "\n",
    "results = {}\n",
    "for v in lam_sl:\n",
    "    r, fig = run_experiment(lam_sl=v)\n",
    "    \n",
    "    results[v] = (r, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot $\\lambda_{SL}$ vs ECE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for l, r in results.items():\n",
    "    x.append(l)\n",
    "    y.append(r[0]['ece'])\n",
    "    \n",
    "plt.loglog(x, y, marker='o', label='SL')\n",
    "plt.plot(x, results[0.0][0]['ece'] * np.ones(len(x)), ls=':', label='MFVI')\n",
    "plt.legend()\n",
    "plt.title(\"$\\lambda_{SL}$ vs ECE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Bayes)",
   "language": "python",
   "name": "bayes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
